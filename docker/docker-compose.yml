version: '3.0'

# 모든 Kafka가 동일한 네트워크 내에서 실행
# 서비스 간의 통신을 격리하고, 필요한 경우 외부 접근을 제한 가능
networks:
  backend:
    driver: bridge
  kafka_network:

# 각 Kafka 브로커는 별도의 Docker 볼륨을 사용하여 데이터 저장소를 유지
# Kafka의 로그 및 데이터 파일이 Docker 컨테이너가 재시작될 때도 유지되도록 한다.
volumes:
  Kafka00:
    driver: local # 도커가 기본으로 제공하는 로컬 드라이버를 사용
  Kafka01:
    driver: local
  Kafka02:
    driver: local
  mysql_data:
    driver: local
  redis_data:
    driver: local
  esdata:
    driver: local

services:
  Kafka00Service:
    image: apache/kafka:latest
    restart: unless-stopped
    container_name: Kafka00Container
    ports:
      - '9092:9092'
      - '10000:10000'
    environment:
      KAFKA_NODE_ID: 0
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:10000
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://Kafka00Service:9092,EXTERNAL://Kafka00Service:10000
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 0@Kafka00Service:9093,1@Kafka01Service:9093,2@Kafka02Service:9093
      KAFKA_CLUSTER_ID: HsDBs9l6UUmQq7Y5E6bNlw
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - kafka_network
      - backend
    volumes:
      - Kafka00:/var/lib/kafka/data

  Kafka01Service:
    image: apache/kafka:latest
    restart: unless-stopped
    container_name: Kafka01Container
    ports:
      - '9093:9092'
      - '10001:10000'
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:10000
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://Kafka01Service:9092,EXTERNAL://Kafka01Service:10001
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 0@Kafka00Service:9093,1@Kafka01Service:9093,2@Kafka02Service:9093
      KAFKA_CLUSTER_ID: HsDBs9l6UUmQq7Y5E6bNlw
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - kafka_network
      - backend
    volumes:
      - Kafka01:/var/lib/kafka/data

  Kafka02Service:
    image: apache/kafka:latest
    restart: unless-stopped
    container_name: Kafka02Container
    ports:
      - '9094:9092'
      - '10002:10000'
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:10000
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://Kafka02Service:9092,EXTERNAL://Kafka02Service:10002
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 0@Kafka00Service:9093,1@Kafka01Service:9093,2@Kafka02Service:9093
      KAFKA_CLUSTER_ID: HsDBs9l6UUmQq7Y5E6bNlw
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - kafka_network
      - backend
    volumes:
      - Kafka02:/var/lib/kafka/data

  KafkaWebUiService:
    image: provectuslabs/kafka-ui:latest
    restart: unless-stopped
    container_name: KafkaWebUiContainer
    ports:
      - '8085:8080' # 호스트의 8085 포트를 컨테이너의 8080 포트에 바인딩
    environment:
      - KAFKA_CLUSTERS_0_NAME=Local-Kraft-Cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=Kafka00Service:9092,Kafka01Service:9092,Kafka02Service:9092 # 초기 브로커 주소 목록 설정, 클러스터의 메타데이터를 가져오고, 클러스터 상태를 모니터링
      - DYNAMIC_CONFIG_ENABLED=true # 동적 설정 변경 허용
      - KAFKA_CLUSTERS_0_AUDIT_TOPICAUDITENABLED=true # 토픽 관련 활동을 감사할 수 있도록 설정
      - KAFKA_CLUSTERS_0_AUDIT_CONSOLEAUDITENABLED=true # 콘솔에서 수행되는 활동을 감사할 수 있도록 설정
    # 서비스가 실행된 후에 시작되도록 설정
    depends_on:
      - Kafka00Service
      - Kafka01Service
      - Kafka02Service
    networks:
      - kafka_network
      - backend

  mysql:
    image: mysql:8.0
    container_name: mysql_container
    restart: unless-stopped
    ports:
      - '3307:3306'
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_DATABASE: chatdb
      MYSQL_USER: guest
      MYSQL_PASSWORD: guest
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - kafka_network
      - backend

  redis:
    image: redis:7.0
    container_name: redis_container
    restart: unless-stopped
    ports:
      - '6380:6379'
    volumes:
      - redis_data:/data
    command: [ "redis-server", "--appendonly", "yes" ]
    networks:
      - kafka_network
      - backend

  debezium:
    image: debezium/connect:3.0.0.Final
    ports:
      - "8083:8083"
    depends_on:
      - mysql
      - Kafka00Service
      - Kafka01Service
      - Kafka02Service
    environment:
      - BOOTSTRAP_SERVERS=Kafka00Service:9092,Kafka01Service:9092,Kafka02Service:9092
      - GROUP_ID=debezium-00
      - CONFIG_STORAGE_TOPIC=DEBEZIUM_CONNECT_CONFIGS
      - OFFSET_STORAGE_TOPIC=DEBEZIUM_CONNECT_OFFSETS
      - STATUS_STORAGE_TOPIC=DEBEZIUM_CONNECT_STATUSES
      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
    networks:
      - kafka_network

  debezium-ui:
    image: debezium/debezium-ui:latest
    container_name: debezium-ui
    ports:
      - "9080:8080"
    depends_on:
      - debezium
    environment:
      - KAFKA_CONNECT_URIS=http://debezium:8083
    networks:
      - kafka_network

  # keycloak:
  #  image: quay.io/keycloak/keycloak:24.0.5
  #  container_name: keycloak
  #  restart: unless-stopped
  #  ports:
  #    - '7070:8080' # Keycloak 콘솔 http://localhost:8080
  #  environment:
  #    # 관리자 계정 (운영에서는 Secret/변수로 교체)
  #    KEYCLOAK_ADMIN: admin
  #    KEYCLOAK_ADMIN_PASSWORD: admin

  #    # DB 설정: MySQL
  #    KC_DB: mysql
  #    KC_DB_USERNAME: guest
  #    KC_DB_PASSWORD: guest
  #    KC_DB_URL_HOST: mysql
  #    KC_DB_URL_PORT: 3306
  #    KC_DB_URL_DATABASE: keycloak    # 아래 init SQL로 미리 생성
  #    KC_HOSTNAME_URL: http://localhost:7070
  #    KC_HOSTNAME_ADMIN_URL: http://localhost:7070
  #    # 호스트네임 (게이트웨이 앞단에서 쓰면 도메인으로 세팅 권장)
  #    # KC_HOSTNAME: localhost
  #    # 데모 환경은 HTTP 허용(운영은 반드시 프록시 뒤 HTTPS)
  #    KC_HTTP_ENABLED: 'true'
  #    # 리버스 프록시(게이트웨이) 뒤라면 'edge' 권장
  #    # KC_PROXY: edge
  #  command:
  #    - start
  #    # realm 자동 import 하고 싶다면 예시:
  #    # - --import-realm
  #  depends_on:
  #    - mysql
  #  networks:
  #    - kafka_network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.2
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - discovery.type=single-node
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false             # ← 추가
      - xpack.security.http.ssl.enabled=false    # ← 추가
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - 9300:9300
      - 9200:9200
    networks:
      backend:
        aliases:
          - "elasticsearch"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.2
    container_name: kibana
    environment:
      ELASTICSEARCH_URL: "http://elasticsearch:9200"
    ports:
      - 5601:5601
    networks:
      backend:
        aliases:
          - "kibana"

  logstash:
    image: docker.elastic.co/logstash/logstash:8.14.2
    container_name: logstash
    command: logstash -f /etc/logstash/conf.d/logstash.conf
    volumes:
      - ./config:/etc/logstash/conf.d
    ports:
      - "5000:5000"
    networks:
      backend:
        aliases:
          - "logstash"

  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    depends_on:
      - elasticsearch
    environment:
      - STORAGE_TYPE=elasticsearch
      - "ES_HOSTS=elasticsearch:9200"
    ports:
      - "9411:9411"
    networks:
      backend:
        aliases:
          - "zipkin"

  configserver:
    image: configserver:latest
    container_name: configserver
    ports:
      - "7071:7071"
    networks:
      backend:
        aliases:
          - "configserver"

  eurekaserver:
    image: eurekaserver:latest
    container_name: eurekaserver
    ports:
      - "8070:8070"
    networks:
      backend:
        aliases:
          - "eurekaserver"

  gatewayserver:
    image: gatewayserver:latest
    container_name: gatewayserver
    ports:
      - "8072:8072"
    networks:
      backend:
        aliases:
          - "gatewayserver"

  nginx:
    image: nginx:latest
    container_name: nginx
    restart: unless-stopped
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - chat-service-1
      - chat-service-2
      - chat-service-3
    networks:
      - backend

  chat-service-1:
    image: chat-service:latest
    container_name: chat-service-1
    environment:
      - CHAT_NODE_ID= chat-messages-group1
      - "ONLINE_KEY_PREFIX=socket:online:1:"
    ports:
      - "8080:8080"
    depends_on:
      - mysql
      - redis
    networks:
      - kafka_network
      - backend

  chat-service-2:
    image: chat-service:latest
    container_name: chat-service-2
    environment:
      - CHAT_NODE_ID=chat-messages-group2
      - "ONLINE_KEY_PREFIX=socket:online:2:"
    ports:
      - "8081:8080"
    depends_on:
      - mysql
      - redis
    networks:
      - kafka_network
      - backend

  chat-service-3:
    image: chat-service:latest
    container_name: chat-service-3
    environment:
      - CHAT_NODE_ID= chat-messages-group3
      - "ONLINE_KEY_PREFIX=socket:online:3:"
    ports:
      - "8082:8080"
    depends_on:
      - mysql
      - redis
    networks:
      - kafka_network
      - backend